{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colaborative filteration\n",
    "\n",
    "> Recsys algorithom from explicit reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.all import *\n",
    "from fastprogress import fastprogress\n",
    "from fastdownload import FastDownload\n",
    "from fastai.tabular.all import *\n",
    "from fastai.tabular.all import *\n",
    "from fastai.collab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch, torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from fastai.learner import to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/MenshikovDmitry/TSU_AI_Course/main/module_1.%20Recommender%2BDevOps/dataset/'\n",
    "files = ('ratings_train.dat ratings_test.dat movies.dat users.dat').split()\n",
    "d = FastDownload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/slakter/.fastdownload/archive/ratings_train.dat'),\n",
       " Path('/home/slakter/.fastdownload/archive/ratings_test.dat'),\n",
       " Path('/home/slakter/.fastdownload/archive/movies.dat'),\n",
       " Path('/home/slakter/.fastdownload/archive/users.dat')]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [d.download(url+f) for f in files]; paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(sep='::', names = ['userId','movieId','rating'], usecols=(0,1,2), engine='python')\n",
    "ratings = pd.read_csv(paths[0], **kwargs)\n",
    "ratings_test = pd.read_csv(paths[1],  **kwargs)\n",
    "movies = pd.read_csv(paths[2], sep='::', names = ['movieId','title'], usecols=(0,1), engine='python', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3539</td>\n",
       "      <td>2478</td>\n",
       "      <td>5</td>\n",
       "      <td>Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1358</td>\n",
       "      <td>2478</td>\n",
       "      <td>1</td>\n",
       "      <td>Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2565</td>\n",
       "      <td>2478</td>\n",
       "      <td>1</td>\n",
       "      <td>Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4819</td>\n",
       "      <td>2478</td>\n",
       "      <td>2</td>\n",
       "      <td>Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5763</td>\n",
       "      <td>2478</td>\n",
       "      <td>1</td>\n",
       "      <td>Three Amigos! (1986)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating                 title\n",
       "0    3539     2478       5  Three Amigos! (1986)\n",
       "1    1358     2478       1  Three Amigos! (1986)\n",
       "2    2565     2478       1  Three Amigos! (1986)\n",
       "3    4819     2478       2  Three Amigos! (1986)\n",
       "4    5763     2478       1  Three Amigos! (1986)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, df_test = ratings.merge(movies), ratings_test.merge(movies)\n",
    "df = df.drop_duplicates(subset = ['userId','title'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['means'] = df.groupby('userId')['rating'].transform(lambda x: x.mean())\n",
    "df['rating'] = df.groupby('userId')['rating'].transform(lambda x: x - x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = CollabDataLoaders.from_df(df, item_name='title', bs=64,valid_pct=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId    6040\n",
       "title     3700\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['userId','title']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "For baseline we can use basic user-item matrix. First convert it to dense matrix. <br>\n",
    "Since number of items and users is small so we can manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.sparse_coo_tensor(tensor(dls.xs).T,tensor(dls.ys).squeeze(),dtype=torch.float32).to_dense().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user-based model to predict user score for movie, we compute <br>\n",
    "$ v = A_uA^T$ to get user similarities by taking dot products, and <br>\n",
    "$r = A^T_mv/\\text{sum}(v)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class CollabUserBased:\n",
    "    def __init__(self, A, device=None): \n",
    "        self.A = A\n",
    "        if not device: to_device(self.A)\n",
    "    \n",
    "    def predict(self, xb, yb=None,loss=F.mse_loss):\n",
    "        u, m = xb.T\n",
    "        ratings = torch.bmm((self.A[u] @ self.A.T)[:,None,:], self.A[:,m].T[...,None]).squeeze()/(self.A[u] @ self.A.T).sum(dim=1)\n",
    "        if yb is not None: return (ratings, loss(ratings,yb[:,0]))\n",
    "        return ratings\n",
    "\n",
    "    def recommend(self, user:int, topk=3):\n",
    "        return ((self.A @ self.A[user]) @ self.A).topk(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CollabUserBased(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.1274, -0.1226,  0.1162,  0.2500,  0.1718,  0.0423, -0.3676, -0.0969,\n",
       "          0.0009,  0.0088,  0.6426,  0.0373,  0.1635,  0.0742,  0.0211,  0.1517,\n",
       "          0.0369,  0.1984, -0.0377, -0.0227,  0.1845,  0.0500,  0.0429, -0.3484,\n",
       "         -0.0223,  0.0136, -0.1631, -0.1036,  0.2529,  0.0361, -0.0212,  0.3728,\n",
       "          0.0634,  0.8883, -0.2202, -0.1393,  0.0068,  0.2256, -0.1129, -0.0577,\n",
       "          0.1371,  0.1907,  0.1258,  0.0430, -0.0528,  0.1193,  0.0505, -0.0168,\n",
       "         -0.0134,  0.4561,  0.0048, -0.0752, -0.1541, -0.0949, -0.1543,  0.2716,\n",
       "          0.8590, -0.0770, -0.0194,  0.1488, -0.1002,  0.1175, -0.0505, -0.0448],\n",
       "        device='cuda:0'),\n",
       " tensor(0.9882, device='cuda:0'))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = to_device(dls.one_batch())\n",
    "model.predict(xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Beauty (1999)\n",
      "Fargo (1996)\n",
      "Star Wars: Episode IV - A New Hope (1977)\n",
      "Being John Malkovich (1999)\n",
      "Usual Suspects, The (1995)\n",
      "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)\n",
      "L.A. Confidential (1997)\n",
      "Pulp Fiction (1994)\n",
      "Raiders of the Lost Ark (1981)\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980)\n"
     ]
    }
   ],
   "source": [
    "_, recs = model.recommend(xb[0][0], topk=10)\n",
    "print('\\n'.join(dls.classes['title'].map_ids(recs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.set_index('userId')\n",
    "\n",
    "df_test['means']= df.drop_duplicates(subset='userId', keep='last').set_index('userId')['means']\n",
    "df_test['rating'] -= df_test['means']\n",
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dls = dls.test_dl(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [model.predict(*to_device(b))[1] for b in test_dls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6256, device='cuda:0')"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(losses).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something smarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
