{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "> cli and web APIs for the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastdownload import FastDownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from collections import deque\n",
    "import logging as l\n",
    "from fastcore.all import *\n",
    "from hits_recsys.collab import *\n",
    "from pathlib import Path\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from importlib import metadata\n",
    "import uvicorn\n",
    "from datetime import date\n",
    "from hits_recsys.embed import EmbedAdapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "DEF_FMT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "\n",
    "def init_logger(name: str = None, level=l.INFO, format: str = None, handlers: list = None, logs_dir='./logs'):\n",
    "    '''Initializes a logger, adds handlers and sets the format. If logs_dir is provided, a file handler is added to the logger.'''\n",
    "    handlers = ifnone(handlers, [])\n",
    "    handlers.append(l.StreamHandler())\n",
    "    if logs_dir: \n",
    "        p = Path(logs_dir)/f'{date.today()}.log'\n",
    "        p.parent.mkdir(parents=True, exist_ok=True)\n",
    "        handlers.append(l.FileHandler(p)) \n",
    "    log_fmt = l.Formatter(ifnone(format, DEF_FMT), datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    log = l.getLogger(name)\n",
    "    log.setLevel(level)\n",
    "    log.handlers.clear()\n",
    "    for h in handlers: h.setFormatter(log_fmt); log.addHandler(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class LoggingQueue(deque):\n",
    "    '''deque with `logging.Handler` api methods'''\n",
    "    def put_nowait(self, rec): self.append(rec.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = LoggingQueue([],3)\n",
    "init_logger(handlers=[l.handlers.QueueHandler(q)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 17:55:55 - root - INFO - test 1\n",
      "2024-04-03 17:55:55 - root - INFO - test 2\n",
      "2024-04-03 17:55:55 - root - INFO - test 3\n"
     ]
    }
   ],
   "source": [
    "l.info(\"test 1\")\n",
    "l.info(\"test 2\")\n",
    "l.info(\"test 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-03 17:55:55 - root - INFO - test 1\n",
      "2024-04-03 17:55:55 - root - INFO - test 2\n",
      "2024-04-03 17:55:55 - root - INFO - test 3\n"
     ]
    }
   ],
   "source": [
    "L(q).pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "MODEL_CLASS ={'collab': CollabUserBased, 'embed': EmbedAdapter}\n",
    "\n",
    "@call_parse\n",
    "def cli(optype: str, # operation to peroform, one of 'train', 'eval' or 'pred'\n",
    "        r_path: Path, # path to dataset with ratings\n",
    "        m_path: Path,  # path to dataset with movie titles\n",
    "        model_type: str = 'collab', # type of model to train, one of `collab`, `embed`\n",
    "        model: Path=None, # path to model if not train\n",
    "        out: Path = './models'):  # folder for output model, by default will save to './models'\n",
    "    \n",
    "    assert optype in ['train','eval','pred'], 'incorrect operation type'\n",
    "    init_logger()\n",
    "    \n",
    "    if model: \n",
    "        l.info(f\"Loading model from {model}\")\n",
    "        serv = ModelService.load(model, MODEL_CLASS[model_type]())\n",
    "    \n",
    "    l.info(f\"loading datasets from {r_path} and {m_path}\")\n",
    "    ds = TfmdDataset(read_movielens(r_path,m_path))\n",
    "    l.info(f\"datasets loaded\")\n",
    "\n",
    "    l.info(f\"start operation: {optype}\")\n",
    "    if optype=='train':\n",
    "        serv = ModelService(MODEL_CLASS[model_type](), ds)\n",
    "        serv.train()\n",
    "        l.info(f\"model trained\")\n",
    "        serv.save(out)\n",
    "        l.info(f\"model saved to {out}\")\n",
    "    elif not serv.model:\n",
    "        l.error(\"You are trying to run model without providing correct model path\")\n",
    "    if optype=='eval':\n",
    "        loss = serv.eval(ds)\n",
    "        l.info(f\"loss = {loss.item()}\")\n",
    "    if optype=='pred':\n",
    "        res = serv.pred(ds)\n",
    "        with open(out, 'w') as f:\n",
    "            f.writelines([f\"{line}\\n\" for line in res])\n",
    "        l.info(f\"preds are saved to {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/MenshikovDmitry/TSU_AI_Course/main/module_1.%20Recommender%2BDevOps/dataset/'\n",
    "files = ('ratings_train.dat ratings_test.dat movies.dat users.dat').split()\n",
    "d = FastDownload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [Path('/home/slakter/.fastdownload/archive/ratings_train.dat'),Path('/home/slakter/.fastdownload/archive/ratings_test.dat'),Path('/home/slakter/.fastdownload/archive/movies.dat'),Path('/home/slakter/.fastdownload/archive/users.dat')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = L(d.download(url+f) for f in files); paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 22:44:38 - root - INFO - loading datasets from /home/slakter/.fastdownload/archive/ratings_train.dat and /home/slakter/.fastdownload/archive/movies.dat\n",
      "2024-03-25 22:44:42 - root - INFO - datasets loaded\n",
      "2024-03-25 22:44:42 - root - INFO - start operation: train\n",
      "2024-03-25 22:44:43 - root - INFO - model trained\n",
      "2024-03-25 22:44:43 - root - INFO - model saved to ../models\n"
     ]
    }
   ],
   "source": [
    "cli('train', paths[0], paths[2], 'collab', out='../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 22:45:31 - root - INFO - Loading model from ../models\n",
      "2024-03-25 22:45:31 - root - INFO - loading datasets from /home/slakter/.fastdownload/archive/ratings_test.dat and /home/slakter/.fastdownload/archive/movies.dat\n",
      "2024-03-25 22:45:32 - root - INFO - datasets loaded\n",
      "2024-03-25 22:45:32 - root - INFO - start operation: pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 22:45:33 - root - INFO - preds are saved to ./out.txt\n"
     ]
    }
   ],
   "source": [
    "cli('pred', paths[1], paths[2], model='../models', out='./out.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PredictRequest(BaseModel):\n",
    "    '''Request for prediction'''\n",
    "    movie_names: list\n",
    "    ratings: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def add_routes(app, serv):\n",
    "    @app.get(\"/api/predict\")\n",
    "    async def predict(body: PredictRequest):\n",
    "        if max(body.ratings) > 5 or min(body.ratings) < 0: \n",
    "            raise HTTPException(400, f\"Ratings not in correct ranges\")\n",
    "        if len(body.ratings) != len(body.movie_names):  \n",
    "            raise HTTPException(400, f\"Not correct number of ratings\")\n",
    "        try:\n",
    "            return serv.recommend(body.movie_names, body.ratings, 20)\n",
    "        except KeyError as e:\n",
    "            raise HTTPException(400, f\"Movie {e.args[0]} not found\")\n",
    "\n",
    "    @app.post(\"/api/reload\")\n",
    "    async def reload(): \n",
    "        serv.load(app.location, app.model_cls())\n",
    "        l.info(\"model reloaded\")\n",
    "\n",
    "    @app.get(\"/api/similar\")\n",
    "    async def similar(movie_name: str):\n",
    "        l.info(f\"getting similar movies to {movie_name}\")\n",
    "        try:\n",
    "            return serv.similar_movies(movie_name)\n",
    "        except KeyError:\n",
    "            raise HTTPException(404, f\"Movie {movie_name} not found\")\n",
    "    \n",
    "    @app.get(\"/api/movies\")\n",
    "    async def movies(prefix:str, page:int=0):\n",
    "        l = [m for m in serv.ds.movie_map if m.startswith(prefix)]\n",
    "        return l[min(20*page,len(l)):min(20*(page+1),len(l))]\n",
    "    \n",
    "    @app.get(\"/api/info\")\n",
    "    async def info():\n",
    "        return dict(metadata.metadata('hits-recsys'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def add_logging(app, q): \n",
    "    @app.get(\"/api/log\")\n",
    "    async def log(page: int = -1, n_logs: int = 20):\n",
    "        logs = list(q)\n",
    "        tail = (page+1)*n_logs\n",
    "        return {'logs': logs[max(page*n_logs,-len(logs)) : None if tail<=0 else tail]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "def serve(host: str='127.0.0.1',\n",
    "          port: int=5000, # port to listen on\n",
    "          model_type:str = 'collab', # type of model to train, one of `collab`, `embed`\n",
    "          model_dir:str='./models', # directory to load model from\n",
    "          logs_dir:str='./logs'): # logs directory\n",
    "    \n",
    "    q = LoggingQueue([], 20)\n",
    "    init_logger(handlers=[l.handlers.QueueHandler(q)], logs_dir=logs_dir)\n",
    "    app = FastAPI()\n",
    "    app.location = model_dir\n",
    "    app.model_cls = MODEL_CLASS[model_type]\n",
    "    serv = ModelService.load(model_dir, app.model_cls())\n",
    "    if not serv.model: \n",
    "          l.error(\"You are trying to run model without providing correct model path! Shutting down...\")\n",
    "          return\n",
    "    add_routes(app, serv)\n",
    "    add_logging(app,q)\n",
    "    serv.save(model_dir)\n",
    "    if in_notebook(): \n",
    "          import nest_asyncio\n",
    "          nest_asyncio.apply()\n",
    "    cfg = uvicorn.Config(app, host=host, port=port, log_config=None)\n",
    "    server = uvicorn.Server(cfg)\n",
    "    server.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 17:56:52 - uvicorn.error - INFO - Started server process [23501]\n",
      "2024-04-03 17:56:52 - uvicorn.error - INFO - Waiting for application startup.\n",
      "2024-04-03 17:56:52 - uvicorn.error - INFO - Application startup complete.\n",
      "2024-04-03 17:56:52 - uvicorn.error - INFO - Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n",
      "2024-04-03 17:56:55 - uvicorn.access - INFO - 127.0.0.1:32806 - \"GET / HTTP/1.1\" 404\n",
      "2024-04-03 17:56:55 - uvicorn.access - INFO - 127.0.0.1:32806 - \"GET /favicon.ico HTTP/1.1\" 404\n",
      "2024-04-03 17:57:05 - uvicorn.access - INFO - 127.0.0.1:33260 - \"GET /api/info HTTP/1.1\" 200\n",
      "2024-04-03 17:57:22 - uvicorn.access - INFO - 127.0.0.1:35924 - \"GET /api/info HTTP/1.1\" 200\n",
      "2024-04-03 17:57:31 - root - DEBUG - start processing user. Sleeping for 60 seconds...\n",
      "2024-04-03 17:58:31 - root - DEBUG - woke up.(assume finished job)...\n",
      "2024-04-03 17:58:31 - uvicorn.access - INFO - 127.0.0.1:35934 - \"GET /api/predict HTTP/1.1\" 200\n",
      "2024-04-03 18:02:24 - root - DEBUG - start processing user. Sleeping for 60 seconds...\n",
      "2024-04-03 18:03:24 - root - DEBUG - woke up.(assume finished job)...\n",
      "2024-04-03 18:03:24 - uvicorn.access - INFO - 127.0.0.1:33800 - \"GET /api/predict HTTP/1.1\" 200\n",
      "2024-04-03 18:03:24 - root - DEBUG - start processing user. Sleeping for 60 seconds...\n",
      "2024-04-03 18:04:24 - root - DEBUG - woke up.(assume finished job)...\n",
      "2024-04-03 18:04:24 - uvicorn.access - INFO - 127.0.0.1:33802 - \"GET /api/predict HTTP/1.1\" 200\n",
      "2024-04-03 18:07:31 - uvicorn.error - INFO - Shutting down\n",
      "2024-04-03 18:07:31 - uvicorn.error - INFO - Waiting for application shutdown.\n",
      "2024-04-03 18:07:31 - uvicorn.error - INFO - Application shutdown complete.\n",
      "2024-04-03 18:07:31 - uvicorn.error - INFO - Finished server process [23501]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "serve(port=5000, model_dir='../models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
